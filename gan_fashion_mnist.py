# -*- coding: utf-8 -*-
"""GAN_fashion_mnist.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QEXDLgK5-ohpsn4YSiiAGu8ssfJb5p7E
"""

!pip install tensorflow tensorflow-gpu matplotlib tensorflow datasets ipywidgets

!pip list
#bringing tensorflow
import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu,True)

gpus

#Bringing in tensorflow datasets for fashion mnist
import tensorflow_datasets as tfds
from matplotlib import pyplot as plt

ds = tfds.load('fashion_mnist',split='train')

ds.as_numpy_iterator().next()

ds.as_numpy_iterator().next().keys()

ds.as_numpy_iterator().next()['image'].shape

import numpy as np

#setup connection aka iterator
dataiterator = ds.as_numpy_iterator()

dataiterator.next()

import numpy as np

np.squeeze(dataiterator.next()["image"]).shape

#Setup the subplot formating
fig,ax = plt.subplots(ncols=4,figsize=(20,20))
#Loop four times and get images
for idx in range(4):
    #grab an image and label
    sample = dataiterator.next()
    #plot the image using specific subplot
    ax[idx].imshow(np.squeeze(sample['image']))
    #appending the image label as the plot title
    ax[idx].title.set_text(sample['label'])

"""four columns
20*20 pixels in size
fig-reference figure
ax individual subplots
setting up the subplots,return values get back are the entire plot,

scale between 0 and 1
"""

#Scale and return images only
def scale_images(data):
  image = data['image']
  return image/255

#Reload the dataset
ds = tfds.load("fashion_mnist",split = "train")
#running the dataset through the scale _images preprocessing step
ds = ds.map(scale_images)
#cache the dataset for that batch
ds = ds.cache()
#shuffle it up
ds = ds.shuffle(60000)
#batch it into 128 images per sample
ds = ds.batch(128)
#reduce the likelihood of bottlenecking
ds = ds.prefetch(64)

ds.as_numpy_iterator().next().shape

"""two models ,
generator will be build to try to generate images of clothing and fashion,
discriminatior will try to learn spot the fakes

generator ,we pass through bunch of random numbers and it will try to take that random numbers to generate some fashion
generative adversal network that actually gives you a little bit more control and this is called conditional gain
the number one maps to specific type of image it actually try to generate that image
sequential
"""

#Bringing  in the sequentialapi for the generator and discriminator
from tensorflow.keras.models import Sequential
#Bringing in the layers for the neural network
from tensorflow.keras.layers import Conv2D,Dense,Flatten,Reshape,LeakyReLU,Dropout
from tensorflow.keras.layers import UpSampling2D # Correct the typo and import explicitly

"""Sequential api means that we take in one input and we get to one output basically flowing one way
LeakyRelu: activation function
Upsampling2D:used in generator to upsample the images and bring add a little depth to or a little bit more space to our image

passing through 128 random values,help generator what to generate from there now this is why i sort of mentioned that you dont have much control
"""

from tensorflow.keras.layers import UpSampling2D

def build_generator():
  model = Sequential()
#takes in random values and reshapes it 7 7 128
  model.add(Dense(7*7*128,input_dim = 128))
  model.add(LeakyReLU(0.2)) # Change LeakyRelu to LeakyReLU
  model.add(Reshape((7,7,128)))

  #Upsmapling block 1
  model.add(UpSampling2D())
  model.add(Conv2D(128,kernel_size = 5,padding ="same")) # Correct the typo here: 'kernal_size' -> 'kernel_size'
  model.add(LeakyReLU(0.2))

   #Upsmapling block 2
  model.add(UpSampling2D())
  model.add(Conv2D(128,kernel_size = 5,padding = "same")) # Correct the typo here as well
  model.add(LeakyReLU(0.2))

  #Convolutional block 1
  model.add(Conv2D(128,4,padding = "same"))
  model.add(LeakyReLU(0.2))

  #Convolutional block 2
  model.add(Conv2D(128,4,padding = "same"))
  model.add(LeakyReLU(0.2))

  #Conv layer to get to one channel
  model.add(Conv2D(1,4,padding="same",activation = "sigmoid"))




  return model

generator = build_generator()

generator.summary()

"""specifying input layer,a fully connected layer or dense connected layer,passing through 128 random values to our generator,
conditional gain focus on what type of image you want to generate ,generate random images from your samplepopulation, we can avoid mode collapse
(mode collapse -genrates a bunch of random different types of images)
convert to image shape 7by7by128
we are applying activations,reshaping it

Upsampling block double this spatial quality 14 by 14 by 128 convolutional layers effectively condense a lttle bit ,128 units,preseve number of channels,kernal size going to be 5 by 5,padding is going to be same ,the activation be LeakyRelu

adding bunch more layers for your generator ,moresophistication,one filter,one channel, image

Downsampling is the reduction in spatial resolution while keeping the same two dimentional(2D) representation .It is typically used to reduce the storage and transmission requirements of images .Upsampling is the incereasing of the spatial resolution while keeping the 2D representation of an image.
"""

img = generator.predict(np.random.randn(4,128,1))
img

img.shape

#Setup the subplot formating
fig,ax = plt.subplots(ncols=4,figsize=(20,20))
#Loop four times and get images
for idx,img in enumerate(img):
    #plot the image using specific subplot
    ax[idx].imshow(np.squeeze(img))
    #appending the image label as the plot title
    ax[idx].title.set_text(idx)

"""impported different modelling components
unique layer take random values and reshapes it to give spacial quality
upsampling to expand thesize of our image ,doubled the size
applied convolutional network layers to give trainable parameters to give more information wahat our output looks like
building blocks increase size from 7 by 128 to 28 to 28 by128 ,additional conv network ,
reduces to one channel,activation of sigmoid to give 0 or 1.

Build a Discriminator
"""

def build_discrimator():
  model = Sequential

  #First Conv Block
  model.add(Conv2D(32,5,input_shape = (28,28,1)))
  model.add(LeakyRelu(0.2))
  model.add(Dropout(0.4))


  return model

discrimator = build_discriminator()

"""32 filters,padding is not same its going to start condensing down the information specifing the input shape is same as output shape of our generator 28by 28by 1 pass through discriminator to determine wheather it is real or fake image
to generate the images by the generator where discriminator thinks it real
"""

discriminator.summary()

















