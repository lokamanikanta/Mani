{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# prepare multi-class classification dataset\n",
        "def create_dataset():\n",
        "    # generate 2d classification dataset\n",
        "    X, y = make_blobs(n_samples=1000, centers=20, n_features=100, cluster_std=2, random_state=2)\n",
        "    # one hot encode output variable\n",
        "    y = to_categorical(y)\n",
        "    # split into train and test\n",
        "    n_train = 500\n",
        "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "    trainy, testy = y[:n_train], y[n_train:]\n",
        "    return trainX, trainy, testX, testy\n",
        "\n",
        "# fit model with given activation function, returns test set accuracy\n",
        "def evaluate_model(activation_function, trainX, trainy, testX, testy):\n",
        "    # configure the model based on the data\n",
        "    n_input, n_classes = trainX.shape[1], trainy.shape[1]\n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(5, input_dim=n_input, activation=activation_function, kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(n_classes, activation='softmax'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.01, momentum=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    # fit model on train set\n",
        "    history = model.fit(trainX, trainy, epochs=100, verbose=0)\n",
        "    # evaluate model on test set\n",
        "    _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "    return history, test_acc\n",
        "\n",
        "# prepare dataset\n",
        "trainX, trainy, testX, testy = create_dataset()\n",
        "\n",
        "# evaluate model and plot learning curve with different activation functions\n",
        "activation_functions = ['relu', 'tanh', 'sigmoid','leaky_relu']\n",
        "results = []\n",
        "\n",
        "for activation_function in activation_functions:\n",
        "    # evaluate model with a given activation function\n",
        "    history, result = evaluate_model(activation_function, trainX, trainy, testX, testy)\n",
        "    results.append((activation_function, result))\n",
        "    # plot learning curve\n",
        "    plt.plot(history.history['loss'], label=activation_function)\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n",
        "# Print test accuracies\n",
        "print(\"Test Accuracies:\")\n",
        "for activation_function, accuracy in results:\n",
        "    print(f\"{activation_function}: {accuracy:.3f}\")"
      ],
      "metadata": {
        "id": "jF9uij7kTceI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Generate a simple classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=20, activation='tanh'))\n",
        "model.add(Dense(32, activation='tanh'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "# Save a visualization of the model architecture\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Manually visualize activations of each layer\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activations = activation_model.predict(X_test[:1])\n",
        "\n",
        "# Visualize activations\n",
        "for i, activation in enumerate(activations):\n",
        "    if len(activation.shape) > 2:\n",
        "        activation = np.squeeze(activation, axis=0)\n",
        "        n_filters = activation.shape[-1]\n",
        "        fig, ax = plt.subplots(1, n_filters, figsize=(20, 2))\n",
        "        for j in range(n_filters):\n",
        "            ax[j].imshow(activation[:, :, j], cmap='viridis')\n",
        "            ax[j].axis('off')\n",
        "        fig.suptitle(f'Layer {i+1} Activations')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f'Layer {i+1} Activation: {activation}')\n",
        "\n",
        "# Show the visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l6pIopUgT2m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression With ANN\n",
        "\n",
        "Input : numeric\n",
        "\n",
        "output : Numeric"
      ],
      "metadata": {
        "id": "u23DkuUSU2W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Generate synthetic regression data\n",
        "X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(10,), activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(1)  # Output layer with no activation for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Save a visualization of the model architecture\n",
        "plot_model(model, to_file='model_plot_regression.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the first few predicted values\n",
        "print(\"Predicted Values:\")\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {predictions[i][0]}, Actual: {y_test[i]}\")"
      ],
      "metadata": {
        "id": "nexVqmRBU1TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Generate synthetic regression data\n",
        "X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(10,), activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(1)  # Output layer with no activation for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Save a visualization of the model architecture\n",
        "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Plot the training and validation loss over epochs\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss_plot.png')\n",
        "plt.show()\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the first few predicted values\n",
        "print(\"Predicted Values:\")\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {predictions[i][0]}, Actual: {y_test[i]}\")\n"
      ],
      "metadata": {
        "id": "cgueQfq1VpzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Generate synthetic binary classification data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(20,), activation='leaky_relu'),\n",
        "    Dense(32, activation='tanh'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "uauyuFAgWGQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Generate synthetic binary classification data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(20,), activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Save a visualization of the model architecture\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "xO9oumdXWRnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}